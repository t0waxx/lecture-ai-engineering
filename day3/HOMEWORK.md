# 第3回 任意課題レポート

## 1. 質問設計の観点と意図

本課題では、RAGの効果を検証するために、以下のような多様な質問を用意した：

| 質問 | 意図 |
|------|------|
| 1. LLMにおけるInference Time Scalingとは？ | モデル単体では知らない可能性の高い新しい概念。講義資料にのみ記載。RAGの効果が顕著に出やすい。|
| 2. 推論時に計算資源を増やすと何が起こる？ | スケーリングに関する直感的問い。講義の説明構造に依存。|
| 3. GPT-o1はどのような特徴を持つか？ | モデル名の誤認識対策や講義の時事性確認。|
| 4. Inference Time Scalingは訓練時の計算と何が違うのか？ | 概念の対比に基づく深い理解を要求。|
| 5. Test-Time Computeのスケーリングは何の性能に影響を与える？ | 間接的な概念理解を確認。|

質問はすべて「LLM2024_day4」講義内で言及された内容に対応しており、モデル単体では回答が困難な設計となっている。

---

## 2. RAGの実装方法と工夫点

実装はGoogle Colab（T4）をベースとし、以下の段階的な改善を行った。

### (1) ベースライン（RAGなし）
- モデル: `google/gemma-2-2b-jpn-it`
- 結果: Inference Time Scalingを従来の「推論時間短縮」と誤認。

### (2) 生の文字起こしテキストを使ったRAG
- `LLM2024_day4_raw.txt`を文単位で分割し、ベクトル検索で上位を抽出。
- 結果: 精度が上がらず、誤情報も含まれた。

### (3) 修正済み文字起こし + チャンク化
- `LLM2024_day4.txt`に対して、文単位の検索結果＋前後2文を付加（文脈ウィンドウ）。
- 結果: 概念の定義に近づいたが、まだノイズ混入あり。

### (4) Rerank導入
- 上位チャンクに対してLLM自身でYes/No判定を行い、関連性の高いもののみ抽出。
- 結果: 無関係な情報の除去に成功。回答の一貫性と正確性が向上。

### (5) 段落ベースの意味的チャンク化
- 文ではなく意味的段落単位で文書を扱い、top-kを再構成。
- 結果: トピックの流れと背景の把握に効果的。

---

## 3. 結果の分析と考察

### ✅ RAGによって改善された点
- 単体モデルでは認識されなかった新概念「Inference Time Scaling」が理解されるようになった。
- 専門用語（GPT-o1など）への誤答が減少。
- 文脈構造を含むチャンクにより、質問と関連する説明のペアを一緒に取得できた。

### ❌ RAGによって悪化した点・限界
- 文単位の検索ではノイズが多く、解釈を誤るケースあり。
- 関連性の低いドキュメントが混入すると、かえって回答が混乱。
- 情報過多により、モデルが正しい判断をしにくくなることもある（特にT4環境では制限が顕著）。

---

## 4. 発展的な改善案（任意）

- **埋め込みモデルの比較**：`infly/inf-retriever-v1-1.5b` 以外のモデル（`intfloat/multilingual-e5`など）での精度比較。
- **スライドウィンドウによるチャンク作成**：被覆率向上のため、文境界の重複を許容した分割。
- **Retrieval Indexの高度化**：FAISS＋メタ情報（講義時間・講師名・スライド参照）の導入。
- **自己評価型RAG**：回答文に対してLLMが自己フィードバックを行うことで品質確認。

---

## 5. 結論

この課題を通じて、RAGが「知識不足の補完」に極めて有効である一方、「文脈の取り扱い」や「情報の質の確保」が非常に重要であることが明らかになった。単純な情報量の増加ではなく、**関連性の高い文脈的情報を厳選するパイプライン設計**が鍵と考えられる。

